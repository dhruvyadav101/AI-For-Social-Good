{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvyadav101/AI-For-Social-Good/blob/main/minor_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "729ap_3AY0zs",
        "outputId": "cab4d98b-bc1b-4916-d879-c2d76c76d73e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay2lCMRcSbMH"
      },
      "outputs": [],
      "source": [
        "#code for text preprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "print(1)\n",
        "# Load dataset\n",
        "df = pd.read_csv('C:\\\\Users\\\\death\\\\Desktop\\\\minor project codes\\\\combined_data.csv')\n",
        "\n",
        "# Function to preprocess tweets\n",
        "def preprocess_tweet(tweet):\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
        "    # Remove hashtags\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # Replace mentions (@user)\n",
        "    tweet = re.sub(r'@[^\\s]+', 'USER', tweet)\n",
        "    # Remove continuously repeated symbols or characters\n",
        "    tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet)\n",
        "    # Convert to lowercase\n",
        "    tweet = tweet.lower()\n",
        "    return tweet\n",
        "print(2)\n",
        "# Apply preprocessing to tweets\n",
        "df['clean_tweet'] = df['tweet'].apply(preprocess_tweet)\n",
        "\n",
        "# Tokenization, Lemmatization, and Stopwords removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(3)\n",
        "def tokenize_and_lemmatize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 1]  # Remove stopwords and single characters\n",
        "    return tokens\n",
        "print(4)\n",
        "# Apply tokenization and lemmatization\n",
        "df['tokenized_tweet'] = df['clean_tweet'].apply(tokenize_and_lemmatize)\n",
        "\n",
        "# Convert tokenized tweets back to strings\n",
        "df['clean_tweet_processed'] = df['tokenized_tweet'].apply(lambda x: ' '.join(x))\n",
        "print(5)\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,3))\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(df['clean_tweet_processed'])\n",
        "print(6)\n",
        "# Save preprocessed data\n",
        "df.to_csv('preprocessed_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5dA815C1jsZ",
        "outputId": "cb324d7f-31bd-4d5c-8385-56d07831fcfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     CONTROL       0.72      0.49      0.58    403165\n",
            "   diagnosed       0.65      0.83      0.73    461988\n",
            "\n",
            "    accuracy                           0.67    865153\n",
            "   macro avg       0.68      0.66      0.66    865153\n",
            "weighted avg       0.68      0.67      0.66    865153\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/modified_file.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHqFQ01f3CtU",
        "outputId": "2761fc21-918c-48d4-c621-16fe20829dbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multi-Layer Perceptron Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     CONTROL       0.72      0.52      0.60    403165\n",
            "   diagnosed       0.66      0.82      0.73    461988\n",
            "\n",
            "    accuracy                           0.68    865153\n",
            "   macro avg       0.69      0.67      0.67    865153\n",
            "weighted avg       0.69      0.68      0.67    865153\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/modified_file.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Multi-Layer Perceptron classifier\n",
        "mlp_classifier = MLPClassifier()\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "print(\"Multi-Layer Perceptron Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKsKVUnhUXWb",
        "outputId": "c24428c2-cb5d-426b-ed7d-87969f07b3ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     CONTROL       0.69      0.53      0.60    403165\n",
            "   diagnosed       0.66      0.79      0.72    461988\n",
            "\n",
            "    accuracy                           0.67    865153\n",
            "   macro avg       0.67      0.66      0.66    865153\n",
            "weighted avg       0.67      0.67      0.66    865153\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/modified_file.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression()\n",
        "lr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY7uaxYrSUPs",
        "outputId": "0ff41dc3-5aae-405a-edd4-719cca1e8ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.6238642182365431\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     CONTROL       0.69      0.36      0.47    403165\n",
            "   diagnosed       0.60      0.86      0.71    461988\n",
            "\n",
            "    accuracy                           0.62    865153\n",
            "   macro avg       0.65      0.61      0.59    865153\n",
            "weighted avg       0.64      0.62      0.60    865153\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/modified_file.csv')\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_tweet_processed'], df['class'], test_size=0.3, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert data to DMatrix format required by XGBoost\n",
        "dtrain = xgb.DMatrix(X_train_tfidf, label=y_train_encoded)\n",
        "dtest = xgb.DMatrix(X_test_tfidf, label=y_test_encoded)\n",
        "\n",
        "# Define XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'multi:softmax',  # Multi-class classification\n",
        "    'num_class': len(label_encoder.classes_),  # Number of classes\n",
        "    'eval_metric': 'merror',  # Evaluation metric\n",
        "    'max_depth': 6,  # Maximum depth of tree\n",
        "    'eta': 0.3,  # Learning rate\n",
        "    'seed': 42  # Random seed for reproducibility\n",
        "}\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = xgb_model.predict(dtest)\n",
        "\n",
        "# Decode predictions\n",
        "y_pred_decoded = label_encoder.inverse_transform(y_pred.astype(int))\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred_decoded)\n",
        "print(\"XGBoost Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_decoded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q7Crvy5VoJG",
        "outputId": "d5dde83e-b340-437e-998a-7474e21b1b31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Classifier Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     CONTROL       0.72      0.48      0.58    403165\n",
            "   diagnosed       0.65      0.84      0.73    461988\n",
            "\n",
            "    accuracy                           0.67    865153\n",
            "   macro avg       0.68      0.66      0.65    865153\n",
            "weighted avg       0.68      0.67      0.66    865153\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/modified_file.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train classifiers\n",
        "nb_classifier = MultinomialNB()\n",
        "mlp_classifier = MLPClassifier()\n",
        "lr_classifier = LogisticRegression()\n",
        "\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "lr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Create a Voting Classifier\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('nb', nb_classifier),\n",
        "    ('mlp', mlp_classifier),\n",
        "    ('lr', lr_classifier)\n",
        "], voting='hard')\n",
        "\n",
        "# Train the Voting Classifier\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred_voting = voting_classifier.predict(X_test)\n",
        "print(\"Voting Classifier Performance:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hhkf7h06pjM",
        "outputId": "8d305092-176a-43ce-a5b1-d80c62364bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ADHD       0.33      0.46      0.38    302606\n",
            "     ANXIETY       0.47      0.04      0.07     58926\n",
            "      AUTISM       0.53      0.09      0.16     81701\n",
            "     BIPOLAR       0.47      0.05      0.08     60502\n",
            "     CONTROL       0.63      0.81      0.71    828478\n",
            "  DEPRESSION       0.49      0.09      0.16    101002\n",
            "         OCD       0.35      0.02      0.04     35798\n",
            "        PTSD       0.49      0.05      0.08     58714\n",
            "\n",
            "    accuracy                           0.54   1527727\n",
            "   macro avg       0.47      0.20      0.21   1527727\n",
            "weighted avg       0.53      0.54      0.49   1527727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/preprocessed_data.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl6nkX_-8dYB",
        "outputId": "b0b3f57c-2559-433c-ce2d-165c2a2cfa0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multi-Layer Perceptron Performance:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ADHD       0.35      0.09      0.14    302606\n",
            "     ANXIETY       0.00      0.00      0.00     58926\n",
            "      AUTISM       1.00      0.00      0.00     81701\n",
            "     BIPOLAR       0.00      0.00      0.00     60502\n",
            "     CONTROL       0.56      0.98      0.71    828478\n",
            "  DEPRESSION       0.00      0.00      0.00    101002\n",
            "         OCD       0.00      0.00      0.00     35798\n",
            "        PTSD       0.00      0.00      0.00     58714\n",
            "\n",
            "    accuracy                           0.55   1527727\n",
            "   macro avg       0.24      0.13      0.11   1527727\n",
            "weighted avg       0.43      0.55      0.41   1527727\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/preprocessed_data.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Multi-Layer Perceptron classifier\n",
        "mlp_classifier = MLPClassifier()\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "print(\"Multi-Layer Perceptron Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVVBhYLp_own",
        "outputId": "3e30fe76-cecd-4147-da2c-a4c26a9a60d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ADHD       0.40      0.16      0.23    302606\n",
            "     ANXIETY       0.46      0.01      0.02     58926\n",
            "      AUTISM       0.47      0.04      0.08     81701\n",
            "     BIPOLAR       0.48      0.01      0.02     60502\n",
            "     CONTROL       0.57      0.96      0.72    828478\n",
            "  DEPRESSION       0.53      0.03      0.05    101002\n",
            "         OCD       0.40      0.01      0.01     35798\n",
            "        PTSD       0.41      0.02      0.03     58714\n",
            "\n",
            "    accuracy                           0.56   1527727\n",
            "   macro avg       0.47      0.16      0.15   1527727\n",
            "weighted avg       0.51      0.56      0.45   1527727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/preprocessed_data.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the text data\n",
        "vectorizer.fit(X)\n",
        "\n",
        "# Convert text data to vectors\n",
        "X_vect = vectorizer.transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression()\n",
        "lr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "y_pred = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qee9hurpCEcX",
        "outputId": "6d0746a9-0515-401c-f390-10f187bc36ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "25234/25234 [==============================] - 4156s 165ms/step - loss: 0.5998 - accuracy: 0.6510 - val_loss: 0.5899 - val_accuracy: 0.6615\n",
            "Epoch 2/5\n",
            "25234/25234 [==============================] - 4108s 163ms/step - loss: 0.5788 - accuracy: 0.6702 - val_loss: 0.5880 - val_accuracy: 0.6607\n",
            "Epoch 3/5\n",
            "13627/25234 [===============>..............] - ETA: 29:01 - loss: 0.5587 - accuracy: 0.6863"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "# Load the preprocessed data\n",
        "df = pd.read_csv('/content/drive/My Drive/modified_file.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df['clean_tweet_processed']\n",
        "y = df['class']  # Assuming 'class' column contains class labels\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Tokenize text data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text data to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_seq_length = max([len(seq) for seq in X_train_seq])\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_seq_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_seq_length)\n",
        "\n",
        "# Define CNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_seq_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_padded, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}